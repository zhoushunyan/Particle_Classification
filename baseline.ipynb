{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\python64\\lib\\site-packages\\ipykernel_launcher.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# 一些常规特征\n",
    "import pandas as pd\n",
    "from tqdm.autonotebook import *\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "data = pd.concat([train, test], axis=0, sort=False).reset_index(drop=True)\n",
    "data = data.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salary_range_min(row):#得到最低工资\n",
    "    try:\n",
    "        result = int(str(row['salary_range']).split('-')[0])\n",
    "    except Exception:\n",
    "        result = -1\n",
    "    return result\n",
    "\n",
    "def salary_range_max(row):#得到最高工资\n",
    "    try:\n",
    "        result = int(str(row['salary_range']).split('-')[1])\n",
    "    except Exception:\n",
    "        result = -1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a9de1045964da890598ee49ca6723e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17880), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b8432f037440fb8dc9a1ca7864ff28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17880), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6576ac96aee548fc8fd55d3a2cb730ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17880), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "normal_feature = pd.DataFrame()#存储特征\n",
    "normal_feature['salary_min'] = data.progress_apply(lambda row:salary_range_min(row), axis=1)\n",
    "normal_feature['salary_max'] = data.progress_apply(lambda row:salary_range_max(row), axis=1)\n",
    "normal_feature['salary_median'] = (normal_feature['salary_max'] + normal_feature['salary_min'])/2#工资的中间值\n",
    "normal_feature['salary_range'] = normal_feature['salary_max'] - normal_feature['salary_min']#工资的最高与最低的差值\n",
    "normal_feature['telecommuting'] = list(data['telecommuting'])#是否远程办公\n",
    "normal_feature['has_company_logo'] = list(data['has_company_logo'])#公司logo\n",
    "normal_feature['has_questions'] = list(data['has_questions'])#\n",
    "from sklearn.preprocessing import LabelEncoder#将值转化为联续的0-n-1的整数。\n",
    "labelencoder = LabelEncoder()\n",
    "normal_feature['employment_type'] = labelencoder.fit_transform(data['employment_type'].astype(str))\n",
    "normal_feature['required_experience'] = labelencoder.fit_transform(data['required_experience'].astype(str))\n",
    "normal_feature['required_education'] = labelencoder.fit_transform(data['required_education'].astype(str))\n",
    "normal_feature['industry'] = labelencoder.fit_transform(data['industry'].astype(str))\n",
    "normal_feature['function'] = labelencoder.fit_transform(data['function'].astype(str))\n",
    "\n",
    "data['review'] = data.progress_apply(lambda row:str(row['title']) + ' ' + str(row['location']) + ' ' + str(row['company_profile']) + ' ' + \n",
    "                                   str(row['description']) + ' ' + str(row['department']) + ' ' + str(row['requirements']) + ' ' + str(row['benefits']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始计算tf-idf特征\n",
      "计算结束\n",
      "开始进行一些前期处理\n",
      "处理完毕\n",
      "\n",
      "****开始跑 PassiveAggressiveClassifier ****\n",
      "PassiveAggressiveClassifier 处理完毕\n",
      "五折结果 [0.99039, 0.99039, 0.99209, 0.98869, 0.98699, 0.98869, 0.99321, 0.99377, 0.98981, 0.99095]\n",
      "平均结果 0.990498\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer#调用TF-IDF方法\n",
    "import jieba#结巴分词\n",
    "from tqdm import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_train = data[:len(train)]\n",
    "df_test = data[len(train):]\n",
    "\n",
    "df_train['label'] = df_train['fraudulent'].astype(int)\n",
    "data = pd.concat([df_train, df_test], axis=0, sort=False)\n",
    "data['review'] = data['review'].apply(lambda row:str(row))\n",
    "\n",
    "############################ tf-idf ############################\n",
    "print('开始计算tf-idf特征')\n",
    "tf = TfidfVectorizer(ngram_range=(1, 2), min_df=3, max_df=0.95, use_idf=1, smooth_idf=1, sublinear_tf=1)\n",
    "discuss_tf = tf.fit_transform(data['review']).tocsr()\n",
    "print('计算结束')\n",
    "\n",
    "############################ 切分数据集 ##########################\n",
    "print('开始进行一些前期处理')\n",
    "train_feature = discuss_tf[:len(df_train)]\n",
    "score = df_train['label']\n",
    "test_feature = discuss_tf[len(df_train):]\n",
    "print('处理完毕')\n",
    "\n",
    "######################### 模型函数(返回sklean_stacking结果) ########################1\n",
    "def get_sklearn_classfiy_stacking(clf, train_feature, test_feature, score, model_name, class_number, n_folds, train_num, test_num):\n",
    "    print('\\n****开始跑', model_name, '****')\n",
    "    stack_train = np.zeros((train_num, class_number))\n",
    "    stack_test = np.zeros((test_num, class_number))\n",
    "    score_mean = []\n",
    "    skf = StratifiedKFold(n_splits=n_folds, random_state=1017)\n",
    "    tqdm.desc = model_name\n",
    "    for i, (tr, va) in enumerate(skf.split(train_feature, score)):\n",
    "        clf.fit(train_feature[tr], score[tr])\n",
    "        score_va = clf._predict_proba_lr(train_feature[va])\n",
    "        score_te = clf._predict_proba_lr(test_feature)\n",
    "        score_single = accuracy_score(score[va], clf.predict(train_feature[va]))\n",
    "        score_mean.append(np.around(score_single, 5))\n",
    "        stack_train[va] += score_va\n",
    "        stack_test += score_te\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "    df_stack = pd.DataFrame()\n",
    "    df_stack['tfidf_' + model_name + '_classfiy_{}'.format(1)] = stack[:, 1]\n",
    "    print(model_name, '处理完毕')\n",
    "    return df_stack, score_mean\n",
    "\n",
    "model_list = [\n",
    "    #['LogisticRegression', LogisticRegression(random_state=1017, C=3)],\n",
    "    #['SGDClassifier', SGDClassifier(random_state=1017, loss='log')],\n",
    "    ['PassiveAggressiveClassifier', PassiveAggressiveClassifier(random_state=1017, C=2)],\n",
    "    #['RidgeClassfiy', RidgeClassifier(random_state=1017)],\n",
    "    #['LinearSVC', LinearSVC(random_state=1017)]\n",
    "]\n",
    "\n",
    "stack_feature = pd.DataFrame()\n",
    "for i in model_list:\n",
    "    stack_result, score_mean = get_sklearn_classfiy_stacking(i[1], train_feature, test_feature, score, i[0], 2, 10, len(df_train), len(df_test))\n",
    "    stack_feature = pd.concat([stack_feature, stack_result], axis=1, sort=False)\n",
    "    print('五折结果', score_mean)\n",
    "    print('平均结果', np.mean(score_mean))\n",
    "normal_feature = pd.concat([stack_feature, normal_feature], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "train_feature = normal_feature[:len(train)]\n",
    "test_feature = normal_feature[len(train):]\n",
    "\n",
    "train_feature['label'] = train['fraudulent'].astype(int)\n",
    "not_cols = ['label']\n",
    "cols = [col for col in train_feature.columns if col not in not_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.07805\n",
      "[100]\tvalid_0's binary_logloss: 0.0540237\n",
      "[150]\tvalid_0's binary_logloss: 0.0419406\n",
      "[200]\tvalid_0's binary_logloss: 0.0355778\n",
      "[250]\tvalid_0's binary_logloss: 0.0322363\n",
      "[300]\tvalid_0's binary_logloss: 0.0303885\n",
      "[350]\tvalid_0's binary_logloss: 0.029018\n",
      "[400]\tvalid_0's binary_logloss: 0.0283069\n",
      "[450]\tvalid_0's binary_logloss: 0.0278642\n",
      "[500]\tvalid_0's binary_logloss: 0.0276772\n",
      "[550]\tvalid_0's binary_logloss: 0.027499\n",
      "[600]\tvalid_0's binary_logloss: 0.0276659\n",
      "[650]\tvalid_0's binary_logloss: 0.0275198\n",
      "[700]\tvalid_0's binary_logloss: 0.0273712\n",
      "[750]\tvalid_0's binary_logloss: 0.0273267\n",
      "[800]\tvalid_0's binary_logloss: 0.0273567\n",
      "[850]\tvalid_0's binary_logloss: 0.027406\n",
      "[900]\tvalid_0's binary_logloss: 0.0274855\n",
      "[950]\tvalid_0's binary_logloss: 0.0275765\n",
      "Early stopping, best iteration is:\n",
      "[753]\tvalid_0's binary_logloss: 0.027301\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.076784\n",
      "[100]\tvalid_0's binary_logloss: 0.0522259\n",
      "[150]\tvalid_0's binary_logloss: 0.0400913\n",
      "[200]\tvalid_0's binary_logloss: 0.0336717\n",
      "[250]\tvalid_0's binary_logloss: 0.0303798\n",
      "[300]\tvalid_0's binary_logloss: 0.0281685\n",
      "[350]\tvalid_0's binary_logloss: 0.0271281\n",
      "[400]\tvalid_0's binary_logloss: 0.0265019\n",
      "[450]\tvalid_0's binary_logloss: 0.0263706\n",
      "[500]\tvalid_0's binary_logloss: 0.0263477\n",
      "[550]\tvalid_0's binary_logloss: 0.0263463\n",
      "[600]\tvalid_0's binary_logloss: 0.0266331\n",
      "[650]\tvalid_0's binary_logloss: 0.0267933\n",
      "Early stopping, best iteration is:\n",
      "[495]\tvalid_0's binary_logloss: 0.0263013\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0789703\n",
      "[100]\tvalid_0's binary_logloss: 0.0542365\n",
      "[150]\tvalid_0's binary_logloss: 0.0423382\n",
      "[200]\tvalid_0's binary_logloss: 0.0354096\n",
      "[250]\tvalid_0's binary_logloss: 0.0317337\n",
      "[300]\tvalid_0's binary_logloss: 0.0297252\n",
      "[350]\tvalid_0's binary_logloss: 0.0286596\n",
      "[400]\tvalid_0's binary_logloss: 0.0279095\n",
      "[450]\tvalid_0's binary_logloss: 0.0275965\n",
      "[500]\tvalid_0's binary_logloss: 0.0269978\n",
      "[550]\tvalid_0's binary_logloss: 0.0266607\n",
      "[600]\tvalid_0's binary_logloss: 0.0265196\n",
      "[650]\tvalid_0's binary_logloss: 0.0265924\n",
      "[700]\tvalid_0's binary_logloss: 0.0266158\n",
      "[750]\tvalid_0's binary_logloss: 0.0266805\n",
      "[800]\tvalid_0's binary_logloss: 0.0267147\n",
      "Early stopping, best iteration is:\n",
      "[605]\tvalid_0's binary_logloss: 0.0265155\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0799595\n",
      "[100]\tvalid_0's binary_logloss: 0.0552879\n",
      "[150]\tvalid_0's binary_logloss: 0.0431954\n",
      "[200]\tvalid_0's binary_logloss: 0.0366282\n",
      "[250]\tvalid_0's binary_logloss: 0.0328882\n",
      "[300]\tvalid_0's binary_logloss: 0.0308643\n",
      "[350]\tvalid_0's binary_logloss: 0.0298441\n",
      "[400]\tvalid_0's binary_logloss: 0.029454\n",
      "[450]\tvalid_0's binary_logloss: 0.0292098\n",
      "[500]\tvalid_0's binary_logloss: 0.0291766\n",
      "[550]\tvalid_0's binary_logloss: 0.0293598\n",
      "[600]\tvalid_0's binary_logloss: 0.0295482\n",
      "[650]\tvalid_0's binary_logloss: 0.0296972\n",
      "Early stopping, best iteration is:\n",
      "[488]\tvalid_0's binary_logloss: 0.0291461\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0835676\n",
      "[100]\tvalid_0's binary_logloss: 0.0607045\n",
      "[150]\tvalid_0's binary_logloss: 0.0496109\n",
      "[200]\tvalid_0's binary_logloss: 0.0439916\n",
      "[250]\tvalid_0's binary_logloss: 0.040909\n",
      "[300]\tvalid_0's binary_logloss: 0.039188\n",
      "[350]\tvalid_0's binary_logloss: 0.0382195\n",
      "[400]\tvalid_0's binary_logloss: 0.0379088\n",
      "[450]\tvalid_0's binary_logloss: 0.038561\n",
      "[500]\tvalid_0's binary_logloss: 0.0392191\n",
      "[550]\tvalid_0's binary_logloss: 0.0399825\n",
      "Early stopping, best iteration is:\n",
      "[393]\tvalid_0's binary_logloss: 0.0378768\n",
      "                                           names   imp\n",
      "0   tfidf_PassiveAggressiveClassifier_classfiy_1  3653\n",
      "11                                      industry  1837\n",
      "8                                employment_type  1065\n",
      "12                                      function  1023\n",
      "10                            required_education   721\n",
      "9                            required_experience   716\n",
      "4                                   salary_range   715\n",
      "6                               has_company_logo   621\n",
      "1                                     salary_min   457\n",
      "7                                  has_questions   315\n",
      "3                                  salary_median   300\n",
      "2                                     salary_max   284\n",
      "5                                  telecommuting    83\n",
      "5 Fold result: [0.991518235793045, 0.9932126696832579, 0.9920814479638009, 0.9917986425339367, 0.9886845827439887]\n",
      "mean result: 0.9914591157436057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,roc_auc_score,f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "version = 'lgb_model_normal_feature'\n",
    "\n",
    "def evaluate_5_fold(train_df, test_df, cols, test=False):\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1017)\n",
    "    y_test = 0\n",
    "    oof_train = np.zeros((train_df.shape[0], 1))\n",
    "    mertics_front = []\n",
    "    for i, (train_index, val_index) in enumerate(kf.split(train_df[cols],train_df.label)):\n",
    "        X_train, y_train = train_df.loc[train_index, cols], train_df.label.values[train_index]\n",
    "        X_val, y_val = train_df.loc[val_index, cols], train_df.label.values[val_index]\n",
    "\n",
    "        lgb_train = lgb.Dataset(\n",
    "            X_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(\n",
    "            X_val, y_val,\n",
    "            reference=lgb_train)\n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'learning_rate' : 0.01, \n",
    "            'verbose': 0,\n",
    "#             'metrics':{'binary_error'},\n",
    "#             'num_leaves':32,\n",
    "            'objective':'binary',\n",
    "#             'feature_fraction': 0.2,\n",
    "#             'bagging_fraction':0.7 ,\n",
    "            'seed': 1024,\n",
    "            'nthread': 50,\n",
    "        }\n",
    "        gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        valid_sets=lgb_eval,\n",
    "                        num_boost_round=10000,\n",
    "                        early_stopping_rounds=200,\n",
    "                        verbose_eval=50,\n",
    "                        )\n",
    "        y_pred = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
    "        if test:\n",
    "            y_test += gbm.predict(test_df[cols], num_iteration=gbm.best_iteration)\n",
    "        oof_train[val_index] = np.array(y_pred).reshape(len(val_index), 1)\n",
    "        mertics_front.append(accuracy_score(train_df.label.values[val_index], np.around(y_pred)))\n",
    "    y_test/= 5\n",
    "    feature_list = pd.DataFrame()\n",
    "    feature_list['names'] = cols\n",
    "    feature_list['imp'] = gbm.feature_importance()\n",
    "    feature_list = feature_list.sort_values(by='imp', ascending=False)\n",
    "    print(feature_list)\n",
    "    print('5 Fold result:', mertics_front)\n",
    "    print('mean result:', np.mean(mertics_front))\n",
    "    gc.collect()\n",
    "    return mertics_front, oof_train, y_test, feature_list\n",
    "f_score, oof_train, y_test, imp = evaluate_5_fold(train_feature, test_feature, cols, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.90713518e-01 9.90686176e-01 8.23804718e-01 3.28835094e-04\n",
      " 3.27700025e-04 5.32593043e-02 9.88891829e-01 5.17078442e-04\n",
      " 3.40937965e-04 9.88132639e-01 8.57137531e-01 3.28677832e-04\n",
      " 3.28345605e-04 3.34130507e-04 3.39366499e-04 3.28526770e-04\n",
      " 8.88258903e-02 9.91484732e-01 1.30211567e-03 9.91584143e-01\n",
      " 9.82618251e-01 3.78410813e-04 9.91464963e-01 4.78638602e-04\n",
      " 9.91580764e-01 4.89562966e-03 9.60460461e-01 9.91400940e-01\n",
      " 4.78467210e-04 9.91511882e-01 9.81883620e-01 9.91584143e-01\n",
      " 4.66325840e-04 3.27950076e-04 3.35550626e-04 6.94866113e-04\n",
      " 9.91583340e-01 3.28531915e-04 7.79609738e-01 3.43190659e-04\n",
      " 9.91484732e-01 1.30568406e-03 3.27976440e-04 3.28695515e-04\n",
      " 9.91400940e-01 9.91484732e-01 9.91583633e-01 3.34710228e-01\n",
      " 9.91147387e-01 3.30305151e-04 3.27815649e-04 3.27784316e-04\n",
      " 8.17738268e-02 2.07836999e-03 1.06325927e-02 3.28615547e-04\n",
      " 3.27737419e-04 9.91569502e-01 9.49570432e-01 9.90198308e-01\n",
      " 9.70305732e-01 3.28531915e-04 3.52176829e-04 9.43871324e-01\n",
      " 9.68819771e-01 3.49938586e-04 3.33597644e-04 9.91584143e-01\n",
      " 9.03980593e-01 9.86186248e-01 3.12353688e-03 9.86749965e-01\n",
      " 4.05400016e-04 9.90482373e-01 6.98830948e-01 6.52848783e-02\n",
      " 3.31465769e-04 3.34361481e-04 4.53760751e-04 3.28789677e-04\n",
      " 9.41370492e-01 9.91400940e-01 9.76643562e-01 9.91583633e-01\n",
      " 9.50548408e-01 9.89832324e-01 6.67125611e-01 9.91208685e-01\n",
      " 3.28767608e-04 9.91400940e-01 3.27846684e-04 3.33275078e-04\n",
      " 9.89559883e-01 6.61346716e-04 3.29554772e-04 9.67243890e-02\n",
      " 9.90362892e-01 9.88668867e-01 1.95460865e-02 1.96889998e-01\n",
      " 3.28184022e-04 6.08601910e-04 3.31833430e-04 3.27909971e-04\n",
      " 8.53796739e-03 3.28299208e-04 9.91580994e-01 3.45853769e-04\n",
      " 9.69269180e-01 6.75172985e-02 3.42943142e-04 3.97165901e-01\n",
      " 3.76686825e-04 4.32344075e-03 1.04636649e-02 9.88809931e-01\n",
      " 3.59182124e-04 9.82274093e-01 3.48776277e-04 9.90198308e-01\n",
      " 9.50270033e-01 3.27898017e-04 9.67431169e-01 9.83407808e-01\n",
      " 9.70305732e-01 3.27947355e-04 6.67092204e-01 4.09858623e-04\n",
      " 4.16743378e-04 9.76944732e-01 9.91144666e-01 3.28410234e-04\n",
      " 3.27859582e-04 3.45203442e-04 5.37498237e-01 3.35604944e-04\n",
      " 8.21922105e-01 3.43647677e-04 3.27951420e-04 9.91400940e-01\n",
      " 9.91506840e-01 1.82534599e-01 9.91464963e-01 9.89947118e-01\n",
      " 3.27707047e-04 9.89890148e-01 3.27863236e-04 9.72393512e-01\n",
      " 9.90420888e-01 9.91506840e-01 3.28695515e-04 1.36274620e-01\n",
      " 6.00665451e-04 3.43988005e-04 3.28696357e-04 5.02261213e-01\n",
      " 7.44764706e-01 3.27846684e-04 9.91584143e-01 5.03773176e-02\n",
      " 3.29282677e-04 1.74866659e-02 8.62187896e-01 3.35604944e-04\n",
      " 3.28018908e-04 9.68819771e-01 7.19681298e-01 3.28626368e-04\n",
      " 5.46724226e-04 3.33713432e-04 9.90813571e-01 9.91506840e-01\n",
      " 9.91445777e-01 9.89305845e-01 3.53092579e-04 3.33396494e-04\n",
      " 3.30278691e-04 3.42091817e-04 6.13597104e-04 9.91171118e-01\n",
      " 9.90686176e-01 9.90860512e-01 9.85120007e-01 8.14053365e-01\n",
      " 3.35659998e-04 1.73218176e-02 1.16299795e-02 3.28404327e-04\n",
      " 3.43210814e-04 9.91588501e-01 1.21412553e-03 3.28872394e-04\n",
      " 9.91580459e-01 9.91580764e-01 3.41169737e-04 6.71980368e-01\n",
      " 3.29976636e-04 1.22131957e-03 3.49467007e-04 9.91584074e-01]\n"
     ]
    }
   ],
   "source": [
    "test_change_label = y_test.copy()\n",
    "print(test_change_label)\n",
    "test_change_label[test_change_label>=0.04] = 1\n",
    "test_change_label[test_change_label < 0.04] = 0\n",
    "#test_change_label[test_change_label > 1] = 0\n",
    "result = pd.DataFrame()\n",
    "result['id'] = np.arange(0, len(y_test), 1)\n",
    "result['result'] = np.around(test_change_label)\n",
    "result['result'] = result['result'].astype(int)\n",
    "result.to_csv('result/re2.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    101\n",
       "0     99\n",
       "Name: result, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.result.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
